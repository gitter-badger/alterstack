# alterstack

[![Join the chat at https://gitter.im/masterspline/alterstack](https://badges.gitter.im/masterspline/alterstack.svg)](https://gitter.im/masterspline/alterstack?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

Проект задуман для создания удобного инстумента для работы с корутинами в C++. Каждая созданная сопрограмма имеет свой стек. В проекте используется boost::context, а именно самая низкоуровневая часть от него, которая непосредственно занимается созданием контекста (нового стека) и переключением между стеками (boost::context::make_fcontext и jump_fcontext). Проект изначально нацелен на получение наилучшего быстродействия при создании и переключении контестов (все остальное делает код пользователя).

# Клонирование и создание проекта

```
git clone https://github.com/masterspline/alterstack.git 
mkdir build
cd build
cmake ../alterstack
make -j 2
```
в результате будет собрана статическая библиотека libalterstack.a и тесты в папке ./test

Для использования библиотеки в своем коде (сейчас она умеет запускать только функции с сигнатурой void(intptr_t)) нужно включить единственный заголовочный файл:
```
#include "alterstack/Api.hpp"
```
Сейчас единственный нужный пользователю класс - это alterstack::Task, у которого есть конструктор, деструктор и три публичных метода:
```
void run(::std::function<void()> runnable);
static void yield();
void wait();
```
Конструктор сейчас создает альтернативный стек. 

run запускает задачу на выполнение на том же потоке, из которого ее вызвали, и выполняет ее до тех пор, пока задача сама не передаст управление другой задаче (вызов yield() или wait()).

wait - позволяет дождаться завершения задачи (Task). Может быть вызван как из корутины, так и из потока, в котором выполняется main, например. Работает по разному, подробнее в разделе про планирование.

yield - статический метод. Передает управление другой задаче. Может быть вызван как из корутины, так и из потока, в котором выполняется main, например. Работает по разному, подробнее в разделе про планирование.

В деструкторе ~Task если задаче еще не завершена вызывается Task::wait() чтобы дождаться завершения выполнения корутины прежде, чем освободить ее память.
```
#include "alterstack/Api.hpp" // API пользователя
#include <iostream>

using alterstack::Task;

void ctx_function()
{
    std::cout << "Context function, first part\n";
    Task::yield();
    std::cout << "Context function, second part\n";
    Task::yield();
    std::cout << "Context function, third part\n";
}
int main()
{
    Task task;
    task.run(ctx_function); // Тут этот же поток выполнит первые две строки функции ctx_function
    Task::yield();          // сюда вернется основной поток после первого yield функции контекста и сразу же 
                            // переключит контекст на первую корутину в очереди на выполнение, т.е. вернется 
                            // обратно и выполнит следующие две строки ctx_function
                            // Также возможен вариант, что после первого yield в ctx_function, корутину 
                            // продолжит выполнять другой поток или BgRunner из специального пула потоков
    task::wait();           // дальнейшее выполнение кода main будет преостановлено, но поток OS переключится
    // на первую корутину в очереди на выполнение, т.е. вернется обратно и выполнит
    // последние две строки ctx_function
    return 0;
```
# Планирование задач
У каждой явно созданной задачи есть свой альтернативный стек, но и основной поток (в котором выполняется main или созданный std::thread) тоже имеет свой, только без явного экземпляра Task. Задачу (код+stack), которая выполняется на родном стеке потока, я называю Native, а Task с собственным стеком AlterNative (задача, корутина). Native Task (запущенная из main или std::thread) может выполняться только на своем родном потоке, а AlterNative на любом. Сейчас планировщик сделан так, что потоки OS будут брать задачи из очереди активных, выполнять их код, но при очередном переключении проверяют, что их нативный контекст готов к продолжению выполнения и переключаются на него (т.е. для обычного потока, из которого выполняется main() или созданного пользователем через std::thread при переключении AlterNative задачи приоритетным будет переключиться на свою родную). Также есть специальный пул (сейчас в нем один поток) потоков BgRunner, которые выполняют задачи из очереди и возвращаются в свой нативный контенст (цикл ожидания) только при отсутствии задач в очереди активных. Для чуть большего однообразия работы планировщика для Native задачи создается thread_local экземпляр Task.

Итого, бывают три типа переключения контекста:

1. нативный -> корутина (например, main запустил корутину или выполнил yield(), основной контекст пока ждет, работает корутина)
2. корутина -> корутина (корутина запустила другую корутину, решила переключить контекст по ожиданию или по yield)
3. корутина -> нативный контекст (корутина переключила контекст, а к этому времени нативный контекст оказался готов к выполнению в результате произойдет переключение на него, потому что он в приоритете при смене контекста)

Для возможности возвращения потока OS к нативному контексту создается thread_local переменная std::unique_ptr<Task>, которая описывает Native Task (она защищена unique_ptr, чтобы автоматически удаляться при завершении потока). При переключении задач отслеживается откуда и куда происходит переключение и если указатель на текущую задачу nullptr, то на нее не переключались, т.е. это Native Task. Таким образом алгоритм планировщика при смене контекста такой:

текущая задача    |откуда брать следующую | если следующей нет
------------------|-----------------------|-------------------
Native Task       |Running queue          |ждем на условной переменной
AlterNative Task  | Native, затем running queue|переключаемся на Native и ждем там
BgRunner (в работе)| running queue        |переключаемся на Native (цикл ожидания)

При постановке в очередь готовой корутины делается notify() для условной переменной, на которой ждут BgRunner (условная переменная сама проверяет ждет ли на ней кто-то и если ждет, то переключается в ядро и будит BgRunner), если в очереди готовых к выполнению задач что-то есть, будится один BgRunner. В дальнейшем очереди будут по одной на каждое ядро процессора, чтобы меньше данные между кешами гонять. Таким образом, сейчас в main вызвать yield, то будет выполнена одна корутина из очереди (до момента ее первого переключения контекста), после чего сразу будет сделан переход обратно в main. Если же yield вызвать из корутины, то будет обработана вся очередь активных задач, после чего будет возврат к ней (она будет последней в очереди), при условии, что во время выполнения не произойдет переход к нативному контексту. BgRunner возвращается в цикл ожидания (его нативный контекст), когда очередь активных задач пуста.

#TODO

1. scheduler per core running Tasks queue
3. class Future to wait for data ready
4. Unit Tests
5. Asyncronous Networking (DNS resolver, sockets)

#License

LGPLv3+
